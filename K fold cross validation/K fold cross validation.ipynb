{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5e4f0e",
   "metadata": {},
   "source": [
    "technique used to evaulate and compare the performance of different models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dea4e450",
   "metadata": {},
   "source": [
    "Ways to train your model:\n",
    "A. use all available data for training and test on same dataset\n",
    "B. split the data into training and testing datasets (does not always work Eg. Training on 80 Algebra questions and testing on 20 geometry questions)\n",
    "\n",
    "Here, K fold cross validation comes to the rescue\n",
    "The data is divided into K folds (say 100 samples are folded into 5 folds)\n",
    "Iteration1: [2,3,4,5] folds are used for training and fold [1] is used for testing and note the score\n",
    "Iteration 2: [1,3,4,5] folds are used for training and fold [2] is used for testing and note the score\n",
    "Iteration 3: [1,2,4,5] folds are used for training and fold [3] is used for testing and note the score\n",
    "….. continue….. till all possible iterations are covered\n",
    "\n",
    "Find the Average score… that is the answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eacfa2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d065ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74aabfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9623ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits['data'], digits['target'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10dc0cb",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5caf6d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4393d",
   "metadata": {},
   "source": [
    "### 2. Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85c8f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533824cf",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a8e59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d973afa",
   "metadata": {},
   "source": [
    "Here, if we rerun the train_test_split code, the accuracy score of all models will change.\n",
    "\n",
    "So, in cases like these where there is very  little difference in accuracy scores (and that too might change everytime!!!), We cannot say that any particular model performs better than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5474e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f16513c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ab81df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 3) # creating 3 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f4fcd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training folds include: [3 4 5 6 7 8], testing fold includes: [0 1 2]\n",
      "training folds include: [0 1 2 6 7 8], testing fold includes: [3 4 5]\n",
      "training folds include: [0 1 2 3 4 5], testing fold includes: [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "## Demo Example:\n",
    "\n",
    "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
    "    print(f\"training folds include: {train_index}, testing fold includes: {test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e45559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6b54b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, X_test, y_train, y_test ):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c503efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Logistic regression is: 0.9666666666666667\n",
      "Score of SVC is: 0.9833333333333333\n",
      "Score of Random Forest Classifier is: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score of Logistic regression is: {get_score(LogisticRegression(), X_train, X_test, y_train, y_test)}\")\n",
    "print(f\"Score of SVC is: {get_score(SVC(), X_train, X_test, y_train, y_test)}\")\n",
    "print(f\"Score of Random Forest Classifier is: {get_score(RandomForestClassifier(), X_train, X_test, y_train, y_test)}\")\n",
    "\n",
    "## Nothing New... just a generic function to give the score of all above model without explicitly instantiating and fitting each \n",
    "## model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fac2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aee55862",
   "metadata": {},
   "source": [
    "### K fold Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8e3a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789e8ad",
   "metadata": {},
   "source": [
    "StratifiedKFold is similar to KFold, but slightly better in a way that it uniformly distributes each of the classification categories among all the folds (leaves little or no scope for biasness)\n",
    "\n",
    "The working of both is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85367f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9a4e1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration No. 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Logistic regression is: 0.9232053422370617\n",
      "Score of SVC is: 0.9666110183639399\n",
      "Score of Random Forest Classifier is: 0.9248747913188647\n",
      "iteration No. 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Logistic regression is: 0.9415692821368948\n",
      "Score of SVC is: 0.9816360601001669\n",
      "Score of Random Forest Classifier is: 0.9432387312186978\n",
      "iteration No. 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Logistic regression is: 0.9148580968280468\n",
      "Score of SVC is: 0.9549248747913188\n",
      "Score of Random Forest Classifier is: 0.9148580968280468\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores_lr = []\n",
    "scores_svc = []\n",
    "scores_rf = []\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(digits['data']):\n",
    "    X_train, X_test, y_train, y_test =  digits['data'][train_index],\\\n",
    "                                        digits['data'][test_index],\\\n",
    "                                        digits['target'][train_index],\\\n",
    "                                        digits['target'][test_index]\n",
    "    i+=1\n",
    "    print('iteration No.', i)\n",
    "    \n",
    "    scores_lr.append(get_score(LogisticRegression(), X_train, X_test, y_train, y_test))\n",
    "    scores_svc.append(get_score(SVC(), X_train, X_test, y_train, y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators = 25), X_train, X_test, y_train, y_test))\n",
    "    \n",
    "    print(f\"Score of Logistic regression is: {get_score(LogisticRegression(), X_train, X_test, y_train, y_test)}\")\n",
    "    print(f\"Score of SVC is: {get_score(SVC(), X_train, X_test, y_train, y_test)}\")\n",
    "    print(f\"Score of Random Forest Classifier is: {get_score(RandomForestClassifier(n_estimators = 25), X_train, X_test, y_train, y_test)}\")\n",
    "    \n",
    "print(\"\\n\\n\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8cad219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Logistic Regression Scores:[0.9232053422370617, 0.9415692821368948, 0.9148580968280468]\n",
      "Final SVC Scores:[0.9666110183639399, 0.9816360601001669, 0.9549248747913188]\n",
      "Final Random Forest Classifier Scores:[0.9215358931552587, 0.9398998330550918, 0.9215358931552587]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Logistic Regression Scores:{scores_lr}\")\n",
    "print(f\"Final SVC Scores:{scores_svc}\")\n",
    "print(f\"Final Random Forest Classifier Scores:{scores_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a789e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3013165f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "841e4ed6",
   "metadata": {},
   "source": [
    "the Above code looks a bit messy and is written only for better understanding\n",
    "\n",
    "sklearn has a method for the exact same thing (i.e. cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1ee651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dc9b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adf3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49ff4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Manoj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92222222, 0.86944444, 0.94150418, 0.93871866, 0.89693593])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(), digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc6110a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96111111, 0.94444444, 0.98328691, 0.98885794, 0.93871866])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(), digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c2b1ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93055556, 0.90833333, 0.95821727, 0.97214485, 0.9275766 ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(), digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b95295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7eb7e09",
   "metadata": {},
   "source": [
    "Here, we compared different Models / Classifiers\n",
    "\n",
    "But we can also compare the same model / classifier with different parameters for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35589bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93611111, 0.92222222, 0.95821727, 0.96100279, 0.92479109])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(), digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee5593d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91666667, 0.85833333, 0.90529248, 0.9275766 , 0.8718663 ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators = 10), digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "666052e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93055556, 0.92777778, 0.95821727, 0.95264624, 0.92479109])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators = 50), digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9fdcfdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93888889, 0.90277778, 0.96100279, 0.95821727, 0.92200557])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators = 100), digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c63cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
